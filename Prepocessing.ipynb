{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOgi8+VUFiwagB8VG3+OiQe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RITabayuni/Skripsi_Perbandingan_K-Prototypes_Agglomerative-Gower/blob/main/Prepocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LIBRARY PRERPARATION**"
      ],
      "metadata": {
        "id": "R3TY8sltoHB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kmodes openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2xf3J1Yu3KF",
        "outputId": "48bd9414-0dbe-4da1-fdc6-f4e0d1fbd0fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kmodes\n",
            "  Downloading kmodes-0.12.2-py2.py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.12/dist-packages (from kmodes) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from kmodes) (1.6.1)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.12/dist-packages (from kmodes) (1.16.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from kmodes) (1.5.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.0->kmodes) (3.6.0)\n",
            "Downloading kmodes-0.12.2-py2.py3-none-any.whl (20 kB)\n",
            "Installing collected packages: kmodes\n",
            "Successfully installed kmodes-0.12.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gower kmodes openpyxl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJVkIrLVvX0Z",
        "outputId": "efc64967-d81d-4197-be79-8636cabda5d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gower\n",
            "  Downloading gower-0.1.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: kmodes in /usr/local/lib/python3.12/dist-packages (0.12.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from gower) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from gower) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from kmodes) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from kmodes) (1.5.3)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=0.22.0->kmodes) (3.6.0)\n",
            "Downloading gower-0.1.2-py3-none-any.whl (5.2 kB)\n",
            "Installing collected packages: gower\n",
            "Successfully installed gower-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive, files\n",
        "import glob, os, pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from kmodes.kprototypes import KPrototypes\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.metrics import silhouette_score\n",
        "import gower\n",
        "from scipy.cluster.hierarchy import linkage, fcluster\n",
        "from scipy.spatial.distance import squareform\n",
        "from collections import defaultdict\n",
        "from scipy.cluster.hierarchy import dendrogram"
      ],
      "metadata": {
        "id": "Rsk03W2_u0gu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NORMALISASI KOLOM**"
      ],
      "metadata": {
        "id": "BEfE7vpBoPxB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QREK-adsEyjL",
        "outputId": "71b25abb-d452-4f13-a5bf-5d6283856cf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Found 34 files\n"
          ]
        }
      ],
      "source": [
        "\n",
        "drive.mount('/content/drive')\n",
        "FOLDER = \"Data\"\n",
        "\n",
        "paths = sorted(set(\n",
        "    glob.glob(os.path.join(FOLDER, \"*.csv\")) +\n",
        "    glob.glob(os.path.join(FOLDER, \"*.CSV\")) +\n",
        "    glob.glob(os.path.join(FOLDER, \"*.xlsx\")) +\n",
        "    glob.glob(os.path.join(FOLDER, \"*.xls\"))\n",
        "))\n",
        "print(f\"Found {len(paths)} files\")\n",
        "\n",
        "# Kebijakan drop:\n",
        "DROP_POLICY = \"either\"        # baris dihapus jika system atau location kosong\n",
        "TREAT_UNKNOWN_AS_MISSING = False  # \"Unknown\" tidak dianggap missing\n",
        "\n",
        "# Kolom yang akan dihapus\n",
        "DROP_COLS = [\n",
        "    \"accept_date\",\"domain\",\"ip_address\",\"web_server\",\"reason\",\n",
        "    \"hackmode\",\"mirror_image\",\"state\",\"def_grade\",\"defacement_id\"\n",
        "]\n",
        "\n",
        "BLANK_TOKENS = {\"\", \"nan\", \"none\", \"null\", \"-\", \"--\", \"n/a\", \"na\", \"?\"}\n",
        "\n",
        "def read_any(p):\n",
        "    if p.lower().endswith((\".xlsx\", \".xls\")):\n",
        "        return pd.read_excel(p)\n",
        "    for enc in (\"utf-8\",\"ISO-8859-1\",\"utf-16\"):\n",
        "        try:\n",
        "            return pd.read_csv(p, encoding=enc)\n",
        "        except Exception:\n",
        "            continue\n",
        "    return pd.read_csv(p, engine=\"python\", encoding_errors=\"ignore\")\n",
        "\n",
        "def norm_colnames(df): #normalisasi kolom\n",
        "    df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
        "    return df\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DROP MISSING VALUES**"
      ],
      "metadata": {
        "id": "TqRmgPPBoU2I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def is_missing_series(s: pd.Series, treat_unknown=False):\n",
        "    if s is None:\n",
        "        return pd.Series(True, index=range(0))\n",
        "    # to string lower\n",
        "    s_str = s.astype(str).str.strip().str.lower()\n",
        "    miss = s.isna() | s_str.isin(BLANK_TOKENS)\n",
        "    if treat_unknown:\n",
        "        miss = miss | (s_str == \"unknown\")\n",
        "    return miss\n",
        "\n",
        "monthly_frames = []\n",
        "summary = []\n",
        "\n",
        "for p in paths:\n",
        "    print(\"Reading\", p)\n",
        "    df = read_any(p)\n",
        "    if df is None or len(df) == 0:\n",
        "        print(\"  [skip empty]\")\n",
        "        continue\n",
        "\n",
        "    df = norm_colnames(df)\n",
        "\n",
        "    for col in [\"system\", \"location\"]:\n",
        "        if col not in df.columns:\n",
        "            df[col] = pd.NA\n",
        "\n",
        "    n0 = len(df)\n",
        "\n",
        "    # drop kolom yang tidak dipakai\n",
        "    to_drop = [c for c in DROP_COLS if c in df.columns]\n",
        "    if to_drop:\n",
        "        df = df.drop(columns=to_drop, errors=\"ignore\")\n",
        "\n",
        "    # buat metadata file\n",
        "    base = os.path.basename(p)\n",
        "    df[\"ym\"] = os.path.splitext(base)[0]\n",
        "    df[\"source_file\"] = base\n",
        "\n",
        "    # deteksi missing untuk system/location\n",
        "    miss_system   = is_missing_series(df[\"system\"],   treat_unknown=TREAT_UNKNOWN_AS_MISSING)\n",
        "    miss_location = is_missing_series(df[\"location\"], treat_unknown=TREAT_UNKNOWN_AS_MISSING)\n",
        "\n",
        "    if DROP_POLICY == \"both\":\n",
        "        to_drop_mask = miss_system & miss_location\n",
        "    elif DROP_POLICY == \"either\":\n",
        "        to_drop_mask = miss_system | miss_location\n",
        "    else:\n",
        "        raise ValueError(\"DROP_POLICY harus 'both' atau 'either'\")\n",
        "\n",
        "    dropped = int(to_drop_mask.sum())\n",
        "    kept = n0 - dropped\n",
        "\n",
        "    df = df.loc[~to_drop_mask].copy()\n",
        "\n",
        "    summary.append({\n",
        "        \"file\": base,\n",
        "        \"rows_before\": n0,\n",
        "        \"dropped\": dropped,\n",
        "        \"kept\": kept,\n",
        "        \"drop_policy\": DROP_POLICY,\n",
        "        \"treat_unknown_as_missing\": TREAT_UNKNOWN_AS_MISSING\n",
        "    })\n",
        "\n",
        "    monthly_frames.append(df)\n",
        "\n",
        "raw = pd.concat(monthly_frames, ignore_index=True) if monthly_frames else pd.DataFrame()\n",
        "print(\"Total rows loaded after drop:\", len(raw))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJKDW2_urfAm",
        "outputId": "afd2a3c9-4de9-4e2c-f207-caddba92d76d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202301.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202302.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202303.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202304.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202305.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202306.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202307.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202308.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202309.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202310.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202311.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202312.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202401.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202402.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202403.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202404.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202405.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202406.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202407.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202408.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202409.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202410.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202411.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202412.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202501.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202502.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202503.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202504.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202505.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202506.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202507.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202508.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202509.csv\n",
            "Reading /content/drive/MyDrive/KULIAH/Skripsi/Defacements/Full/Defacements202510.csv\n",
            "Total rows loaded after drop: 331901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# simpan data setelah drop\n",
        "raw.to_csv(\"full_data_after_drop_all_months.csv\", index=False)\n",
        "print(\"Saved combined full data -> full_data_after_drop_all_months.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGbiVtIRXClS",
        "outputId": "c264b561-9935-4e24-9d3e-96b373609042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved combined full data -> full_data_after_drop_all_months.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DEDUPLIKASI TIPE SERANGAN**"
      ],
      "metadata": {
        "id": "rLQV-y59olNH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "COL_YM        = \"ym\"\n",
        "COL_ATTACKER  = \"attacker\"\n",
        "COL_LOCATION  = \"location\"\n",
        "COL_TYPE      = \"type\"\n",
        "COL_ADD_DATE  = \"add_date\"\n",
        "COL_REDEF     = \"redefacement\"\n",
        "COL_SYSTEM    = \"system\"\n",
        "\n",
        "\n",
        "# Deduplikasi:\n",
        "# - Mass akan dedup pakai level tanggal (YYYY-MM-DD) secara default\n",
        "# - Regular akan dedup pakai timestamp penuh secara default\n",
        "DEDUP_USE_ADD_DATE_DAY_MASS     = True\n",
        "DEDUP_USE_ADD_DATE_DAY_REGULAR  = False\n",
        "\n",
        "\n",
        "def ensure_datetime_day_key(s: pd.Series) -> pd.Series:\n",
        "    # Ambil kunci harian (YYYY-MM-DD) dari kolom datetime/string\n",
        "    if np.issubdtype(s.dtype, np.datetime64):\n",
        "        return s.dt.date.astype(str)\n",
        "    return pd.to_datetime(s, errors=\"coerce\").dt.date.astype(str)\n",
        "\n",
        "\n",
        "def to_string_key(s: pd.Series) -> pd.Series:\n",
        "    # Pakai string apa adanya (untuk timestamp penuh atau teks)\n",
        "    if np.issubdtype(s.dtype, np.datetime64):\n",
        "        return s.astype(\"datetime64[ns]\").astype(str)\n",
        "    return s.astype(str)\n",
        "\n",
        "\n",
        "def is_mass_type(series: pd.Series) -> pd.Series:\n",
        "    return series.astype(str).str.lower().str.contains(\"mass\")\n",
        "\n",
        "\n",
        "def dedup_all_global(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    required = [COL_TYPE, COL_ATTACKER, COL_ADD_DATE, COL_LOCATION, COL_REDEF, COL_SYSTEM]\n",
        "    missing = [c for c in required if c not in df.columns]\n",
        "    if missing:\n",
        "        print(f\"[WARN] Lewatkan dedup karena kolom wajib hilang: {missing}\")\n",
        "        return df\n",
        "\n",
        "    # ===== TOTAL SEBELUM =====\n",
        "    before_total = len(df)\n",
        "\n",
        "    mask_mass = is_mass_type(df[COL_TYPE])\n",
        "\n",
        "    # key untuk MASS\n",
        "    if DEDUP_USE_ADD_DATE_DAY_MASS:\n",
        "        add_key_mass = ensure_datetime_day_key(df[COL_ADD_DATE])\n",
        "    else:\n",
        "        add_key_mass = to_string_key(df[COL_ADD_DATE])\n",
        "\n",
        "    # key untuk REGULAR\n",
        "    if DEDUP_USE_ADD_DATE_DAY_REGULAR:\n",
        "        add_key_reg = ensure_datetime_day_key(df[COL_ADD_DATE])\n",
        "    else:\n",
        "        add_key_reg = to_string_key(df[COL_ADD_DATE])\n",
        "\n",
        "    # ===== MASS =====\n",
        "    mass_part = df[mask_mass].copy()\n",
        "    if not mass_part.empty:\n",
        "        mass_part = mass_part.assign(_add_key=add_key_mass[mask_mass])\n",
        "        mass_part = mass_part.sort_values(\n",
        "            [COL_ATTACKER, \"_add_key\", COL_LOCATION, COL_REDEF, COL_SYSTEM],\n",
        "            kind=\"stable\"\n",
        "        )\n",
        "        before_mass = len(mass_part)\n",
        "        mass_part = mass_part.drop_duplicates(\n",
        "            subset=[COL_ATTACKER, \"_add_key\", COL_LOCATION, COL_REDEF, COL_SYSTEM],\n",
        "            keep=\"first\"\n",
        "        ).drop(columns=[\"_add_key\"], errors=\"ignore\")\n",
        "        after_mass = len(mass_part)\n",
        "    else:\n",
        "        before_mass = after_mass = 0\n",
        "\n",
        "    # ===== REGULAR =====\n",
        "    regular_part = df[~mask_mass].copy()\n",
        "    if not regular_part.empty:\n",
        "        regular_part = regular_part.assign(_add_key=add_key_reg[~mask_mass])\n",
        "        regular_part = regular_part.sort_values(\n",
        "            [COL_TYPE, COL_ATTACKER, \"_add_key\", COL_LOCATION, COL_REDEF, COL_SYSTEM],\n",
        "            kind=\"stable\"\n",
        "        )\n",
        "        before_reg = len(regular_part)\n",
        "        regular_part = regular_part.drop_duplicates(\n",
        "            subset=[COL_TYPE, COL_ATTACKER, \"_add_key\", COL_LOCATION, COL_REDEF, COL_SYSTEM],\n",
        "            keep=\"first\"\n",
        "        ).drop(columns=[\"_add_key\"], errors=\"ignore\")\n",
        "        after_reg = len(regular_part)\n",
        "    else:\n",
        "        before_reg = after_reg = 0\n",
        "\n",
        "    out = pd.concat([regular_part, mass_part], ignore_index=True)\n",
        "\n",
        "    # ===== TOTAL SESUDAH =====\n",
        "    after_total = len(out)\n",
        "    removed_total = before_total - after_total\n",
        "\n",
        "    # (opsional tapi berguna) print ringkas\n",
        "    print(f\"[DEDUP] Total: {before_total:,} -> {after_total:,} (removed {removed_total:,})\")\n",
        "    print(f\"[DEDUP] Regular: {before_reg:,} -> {after_reg:,} (removed {before_reg-after_reg:,})\")\n",
        "    print(f\"[DEDUP] Mass: {before_mass:,} -> {after_mass:,} (removed {before_mass-after_mass:,})\")\n",
        "\n",
        "    return out\n",
        "\n",
        "raw = dedup_all_global(raw)\n",
        "\n"
      ],
      "metadata": {
        "id": "-hSX7KTPrlyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb2281f-6ab9-41d3-dcd2-69f0148956a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[DEDUP] Total: 331,901 -> 141,560 (removed 190,341)\n",
            "[DEDUP] Regular: 144,668 -> 131,182 (removed 13,486)\n",
            "[DEDUP] Mass: 187,233 -> 10,378 (removed 176,855)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SIMPAN DATA SETELAH DEDUPLIKASI**"
      ],
      "metadata": {
        "id": "660CLX3aoraU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw.to_csv(\"data_after_dedup.csv\", index=False)\n",
        "print(\"Saved combined full data -> data_after_dedup.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j824YQssXcoa",
        "outputId": "331c990d-a8de-4d24-ca98-a93e652e4eb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved combined full data -> data_after_dedup.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SIMPLE RANDOM SAMPLING DAN PENGKATEGORIAN TOP 10 ATTACKER LOCATION**"
      ],
      "metadata": {
        "id": "ux5vB-_fowyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "def add_year_month_from_ym(df, col_ym=\"ym\"):\n",
        "    if col_ym not in df.columns:\n",
        "        return df\n",
        "    s = df[col_ym].astype(str)\n",
        "    yyyymm = s.str.extract(r\"(\\d{6})$\", expand=False)\n",
        "    df[\"year\"]  = pd.to_numeric(yyyymm.str[:4], errors=\"coerce\")\n",
        "    df[\"month\"] = pd.to_numeric(yyyymm.str[4:6], errors=\"coerce\")\n",
        "    return df\n",
        "\n",
        "def topk_coverage(series, ks=(5,10,15,20,30,50)):\n",
        "    s = series.fillna(\"NA\").astype(str)\n",
        "    vc = s.value_counts(normalize=True) * 100\n",
        "    out = {}\n",
        "    for k in ks:\n",
        "        out[k] = float(vc.head(k).sum())\n",
        "    return out\n",
        "\n",
        "def apply_topk_to_newcol(df, src_col, dst_col, k=10, other=\"Other\"):\n",
        "    s = df[src_col].fillna(\"NA\").astype(str)\n",
        "    top = set(s.value_counts().head(k).index)\n",
        "    df[dst_col] = s.where(s.isin(top), other)\n",
        "    return df\n",
        "\n",
        "def random_sample_pipeline(\n",
        "    raw,\n",
        "    frac,\n",
        "    out_dir,\n",
        "    random_state=42,\n",
        "    # kolom\n",
        "    col_ym=\"ym\",\n",
        "    col_attacker=\"attacker\",\n",
        "    col_location=\"location\",\n",
        "    # output grouping (kolom baru)\n",
        "    attacker_group_col=\"attacker_group\",\n",
        "    location_group_col=\"location_group\",\n",
        "    topk_attacker=10,\n",
        "    topk_location=10,\n",
        "    other=\"Other\",\n",
        "    # flags\n",
        "    do_topk=True,\n",
        "    do_coverage=True,\n",
        "    # drop sebelum clustering\n",
        "    drop_cols_for_clustering=(\"ym\", \"source_file\")\n",
        "):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    # 1) random sampling\n",
        "    N = len(raw)\n",
        "    n_target = int(round(N * frac))\n",
        "    n_target = min(n_target, N)\n",
        "\n",
        "    sampled = raw.sample(n=n_target, replace=False, random_state=random_state).copy()\n",
        "    print(f\"\\n=== {int(frac*100)}% RANDOM | n={len(sampled):,} ===\")\n",
        "\n",
        "    # 2) tambah year & month\n",
        "    sampled = add_year_month_from_ym(sampled, col_ym=col_ym)\n",
        "\n",
        "    # 3) Top-K GLOBAL\n",
        "    if do_topk:\n",
        "        if col_attacker in sampled.columns:\n",
        "            sampled = apply_topk_to_newcol(\n",
        "                sampled, src_col=col_attacker, dst_col=attacker_group_col,\n",
        "                k=topk_attacker, other=other\n",
        "            )\n",
        "        if col_location in sampled.columns:\n",
        "            sampled = apply_topk_to_newcol(\n",
        "                sampled, src_col=col_location, dst_col=location_group_col,\n",
        "                k=topk_location, other=other\n",
        "            )\n",
        "\n",
        "    # drop ym & source_file\n",
        "    cluster_df = sampled.drop(\n",
        "        columns=[c for c in drop_cols_for_clustering if c in sampled.columns],\n",
        "        errors=\"ignore\"\n",
        "    )\n",
        "\n",
        "    out_cluster = os.path.join(out_dir, f\"{int(frac*100)}%_random_sampled.csv\")\n",
        "    cluster_df.to_csv(out_cluster, index=False)\n",
        "    print(\"Saved (for clustering) ->\", out_cluster)\n",
        "\n",
        "    # 7) tampilkan top months (display only)\n",
        "    if col_ym in sampled.columns:\n",
        "        print(\"\\nTop months (count) [display only]:\")\n",
        "        print(sampled.groupby(col_ym).size().rename(\"n\").sort_values(ascending=False).head(15))\n",
        "\n",
        "    return sampled, cluster_df\n"
      ],
      "metadata": {
        "id": "jTLufklkeLSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PANGGIL FUNCTION**"
      ],
      "metadata": {
        "id": "gymzX9Xfo9L6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUT_DIR = \"Data\"\n",
        "\n",
        "s10, s10_cluster = random_sample_pipeline(raw, 0.10, OUT_DIR, random_state=42)\n",
        "s20, s20_cluster = random_sample_pipeline(raw, 0.20, OUT_DIR, random_state=42)\n",
        "s30, s30_cluster = random_sample_pipeline(raw, 0.30, OUT_DIR, random_state=42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70Hac-1zeVVX",
        "outputId": "8c869882-8f34-4096-bfe1-c69e65e1960f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 10% RANDOM | n=14,156 ===\n",
            "Saved (for clustering) -> /content/drive/MyDrive/KULIAH/Skripsi/Defacements/RandomSampled/10%_random_sampled.csv\n",
            "\n",
            "Top months (count) [display only]:\n",
            "ym\n",
            "Defacements202510    960\n",
            "Defacements202301    853\n",
            "Defacements202303    764\n",
            "Defacements202304    700\n",
            "Defacements202302    586\n",
            "Defacements202305    522\n",
            "Defacements202403    522\n",
            "Defacements202308    509\n",
            "Defacements202509    507\n",
            "Defacements202307    499\n",
            "Defacements202507    460\n",
            "Defacements202404    447\n",
            "Defacements202405    441\n",
            "Defacements202505    420\n",
            "Defacements202406    412\n",
            "Name: n, dtype: int64\n",
            "\n",
            "=== 20% RANDOM | n=28,312 ===\n",
            "Saved (for clustering) -> /content/drive/MyDrive/KULIAH/Skripsi/Defacements/RandomSampled/20%_random_sampled.csv\n",
            "\n",
            "Top months (count) [display only]:\n",
            "ym\n",
            "Defacements202510    1922\n",
            "Defacements202301    1662\n",
            "Defacements202303    1570\n",
            "Defacements202304    1343\n",
            "Defacements202302    1166\n",
            "Defacements202305    1089\n",
            "Defacements202509    1056\n",
            "Defacements202308    1023\n",
            "Defacements202403    1018\n",
            "Defacements202307     960\n",
            "Defacements202507     906\n",
            "Defacements202405     863\n",
            "Defacements202404     852\n",
            "Defacements202506     846\n",
            "Defacements202505     834\n",
            "Name: n, dtype: int64\n",
            "\n",
            "=== 30% RANDOM | n=42,468 ===\n",
            "Saved (for clustering) -> /content/drive/MyDrive/KULIAH/Skripsi/Defacements/RandomSampled/30%_random_sampled.csv\n",
            "\n",
            "Top months (count) [display only]:\n",
            "ym\n",
            "Defacements202510    2888\n",
            "Defacements202301    2459\n",
            "Defacements202303    2414\n",
            "Defacements202304    2012\n",
            "Defacements202302    1795\n",
            "Defacements202305    1667\n",
            "Defacements202308    1550\n",
            "Defacements202403    1517\n",
            "Defacements202509    1503\n",
            "Defacements202307    1420\n",
            "Defacements202507    1341\n",
            "Defacements202405    1283\n",
            "Defacements202404    1278\n",
            "Defacements202506    1272\n",
            "Defacements202505    1271\n",
            "Name: n, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s15, s15_cluster = random_sample_pipeline(raw, 0.15, OUT_DIR, random_state=42)\n",
        "s16, s16_cluster = random_sample_pipeline(raw, 0.16, OUT_DIR, random_state=42)\n",
        "s17, s17_cluster = random_sample_pipeline(raw, 0.17, OUT_DIR, random_state=42)\n",
        "s18, s18_cluster = random_sample_pipeline(raw, 0.18, OUT_DIR, random_state=42)\n",
        "s19, s19_cluster = random_sample_pipeline(raw, 0.19, OUT_DIR, random_state=42)"
      ],
      "metadata": {
        "id": "6zHj9fRL5UtG",
        "outputId": "4419143e-e0d8-4323-bad0-e19e84736163",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== 15% RANDOM | n=21,234 ===\n",
            "Saved (for clustering) -> /content/drive/MyDrive/KULIAH/Skripsi/Defacements/RandomSampled/15%_random_sampled.csv\n",
            "\n",
            "Top months (count) [display only]:\n",
            "ym\n",
            "Defacements202510    1452\n",
            "Defacements202301    1253\n",
            "Defacements202303    1158\n",
            "Defacements202304    1040\n",
            "Defacements202302     882\n",
            "Defacements202305     809\n",
            "Defacements202509     801\n",
            "Defacements202403     790\n",
            "Defacements202308     760\n",
            "Defacements202307     720\n",
            "Defacements202507     658\n",
            "Defacements202405     653\n",
            "Defacements202505     626\n",
            "Defacements202404     622\n",
            "Defacements202506     612\n",
            "Name: n, dtype: int64\n",
            "\n",
            "=== 16% RANDOM | n=22,650 ===\n",
            "Saved (for clustering) -> /content/drive/MyDrive/KULIAH/Skripsi/Defacements/RandomSampled/16%_random_sampled.csv\n",
            "\n",
            "Top months (count) [display only]:\n",
            "ym\n",
            "Defacements202510    1554\n",
            "Defacements202301    1321\n",
            "Defacements202303    1229\n",
            "Defacements202304    1099\n",
            "Defacements202302     936\n",
            "Defacements202305     872\n",
            "Defacements202509     856\n",
            "Defacements202403     840\n",
            "Defacements202308     822\n",
            "Defacements202307     767\n",
            "Defacements202507     705\n",
            "Defacements202405     696\n",
            "Defacements202506     672\n",
            "Defacements202404     672\n",
            "Defacements202505     665\n",
            "Name: n, dtype: int64\n",
            "\n",
            "=== 17% RANDOM | n=24,065 ===\n",
            "Saved (for clustering) -> /content/drive/MyDrive/KULIAH/Skripsi/Defacements/RandomSampled/17%_random_sampled.csv\n",
            "\n",
            "Top months (count) [display only]:\n",
            "ym\n",
            "Defacements202510    1650\n",
            "Defacements202301    1414\n",
            "Defacements202303    1318\n",
            "Defacements202304    1156\n",
            "Defacements202302     987\n",
            "Defacements202305     920\n",
            "Defacements202509     904\n",
            "Defacements202403     888\n",
            "Defacements202308     874\n",
            "Defacements202307     812\n",
            "Defacements202507     752\n",
            "Defacements202405     751\n",
            "Defacements202506     720\n",
            "Defacements202404     706\n",
            "Defacements202505     702\n",
            "Name: n, dtype: int64\n",
            "\n",
            "=== 18% RANDOM | n=25,481 ===\n",
            "Saved (for clustering) -> /content/drive/MyDrive/KULIAH/Skripsi/Defacements/RandomSampled/18%_random_sampled.csv\n",
            "\n",
            "Top months (count) [display only]:\n",
            "ym\n",
            "Defacements202510    1741\n",
            "Defacements202301    1490\n",
            "Defacements202303    1400\n",
            "Defacements202304    1240\n",
            "Defacements202302    1051\n",
            "Defacements202305     981\n",
            "Defacements202509     954\n",
            "Defacements202403     939\n",
            "Defacements202308     911\n",
            "Defacements202307     859\n",
            "Defacements202507     802\n",
            "Defacements202405     785\n",
            "Defacements202506     765\n",
            "Defacements202404     759\n",
            "Defacements202505     750\n",
            "Name: n, dtype: int64\n",
            "\n",
            "=== 19% RANDOM | n=26,896 ===\n",
            "Saved (for clustering) -> /content/drive/MyDrive/KULIAH/Skripsi/Defacements/RandomSampled/19%_random_sampled.csv\n",
            "\n",
            "Top months (count) [display only]:\n",
            "ym\n",
            "Defacements202510    1837\n",
            "Defacements202301    1574\n",
            "Defacements202303    1490\n",
            "Defacements202304    1286\n",
            "Defacements202302    1115\n",
            "Defacements202305    1026\n",
            "Defacements202509     993\n",
            "Defacements202403     971\n",
            "Defacements202308     969\n",
            "Defacements202307     912\n",
            "Defacements202507     860\n",
            "Defacements202405     829\n",
            "Defacements202404     805\n",
            "Defacements202506     804\n",
            "Defacements202505     788\n",
            "Name: n, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}